{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: MÃ´ hÃ¬nh Dá»± Ä‘oÃ¡n Khoáº£ng GiÃ¡ NhÃ  (Prediction Intervals)\n",
    "\n",
    "## Má»¥c tiÃªu\n",
    "- XÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n khoáº£ng giÃ¡ nhÃ  (lower bound, upper bound)\n",
    "- So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p: Quantile Regression, LightGBM, Ensemble\n",
    "- Tá»‘i Æ°u hÃ³a Mean Interval Width trÃªn Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import thÆ° viá»‡n\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import QuantileRegressor, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cáº¥u hÃ¬nh\n",
    "plt.style.use('seaborn-v0_8')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ tá»« Q1\n",
    "try:\n",
    "    X_train = pd.read_csv('processed_data/X_train_processed.csv')\n",
    "    X_test = pd.read_csv('processed_data/X_test_processed.csv')\n",
    "    y_train = pd.read_csv('processed_data/y_train.csv')['SalePrice']\n",
    "    scaler = joblib.load('processed_data/scaler.pkl')\n",
    "    \n",
    "    print(f\"âœ… Loaded processed data successfully\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Processed data not found. Please run Q1 notebook first.\")\n",
    "    # Fallback: load raw data\n",
    "    print(\"Loading raw data as fallback...\")\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    \n",
    "    # Basic preprocessing\n",
    "    numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "    X_train = train_df[numeric_cols].drop('SalePrice', axis=1).fillna(0)\n",
    "    y_train = train_df['SalePrice']\n",
    "    X_test = test_df[numeric_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prediction Intervals Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionIntervalModel:\n",
    "    def __init__(self, alpha=0.1, random_state=42):\n",
    "        \"\"\"\n",
    "        alpha: significance level (0.1 for 90% confidence interval)\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.lower_quantile = alpha / 2\n",
    "        self.upper_quantile = 1 - alpha / 2\n",
    "        self.random_state = random_state\n",
    "        self.models = {}\n",
    "        \n",
    "    def calculate_interval_width(self, lower_pred, upper_pred):\n",
    "        \"\"\"TÃ­nh Ä‘á»™ rá»™ng interval trung bÃ¬nh\"\"\"\n",
    "        return np.mean(upper_pred - lower_pred)\n",
    "    \n",
    "    def calculate_coverage_rate(self, y_true, lower_pred, upper_pred):\n",
    "        \"\"\"TÃ­nh tá»· lá»‡ coverage\"\"\"\n",
    "        covered = (y_true >= lower_pred) & (y_true <= upper_pred)\n",
    "        return np.mean(covered)\n",
    "    \n",
    "    def evaluate_intervals(self, y_true, lower_pred, upper_pred):\n",
    "        \"\"\"ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng prediction intervals\"\"\"\n",
    "        width = self.calculate_interval_width(lower_pred, upper_pred)\n",
    "        coverage = self.calculate_coverage_rate(y_true, lower_pred, upper_pred)\n",
    "        \n",
    "        return {\n",
    "            'mean_interval_width': width,\n",
    "            'coverage_rate': coverage,\n",
    "            'target_coverage': 1 - self.alpha\n",
    "        }\n",
    "\n",
    "# Khá»Ÿi táº¡o model\n",
    "pi_model = PredictionIntervalModel(alpha=0.1)  # 90% confidence interval\n",
    "print(f\"Prediction Interval Model initialized\")\n",
    "print(f\"Target coverage: {1-pi_model.alpha:.1%}\")\n",
    "print(f\"Lower quantile: {pi_model.lower_quantile:.3f}\")\n",
    "print(f\"Upper quantile: {pi_model.upper_quantile:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PhÆ°Æ¡ng phÃ¡p 1: Quantile Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_regression_approach(X_train, y_train, X_test, alpha=0.1):\n",
    "    \"\"\"PhÆ°Æ¡ng phÃ¡p Quantile Regression\"\"\"\n",
    "    lower_quantile = alpha / 2\n",
    "    upper_quantile = 1 - alpha / 2\n",
    "    \n",
    "    print(f\"ðŸ”§ Training Quantile Regression models...\")\n",
    "    \n",
    "    # Model cho quantile dÆ°á»›i\n",
    "    print(f\"   Training lower quantile model ({lower_quantile:.3f})...\")\n",
    "    lower_model = QuantileRegressor(\n",
    "        quantile=lower_quantile, \n",
    "        alpha=0.01, \n",
    "        solver='highs'\n",
    "    )\n",
    "    lower_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Model cho quantile trÃªn\n",
    "    print(f\"   Training upper quantile model ({upper_quantile:.3f})...\")\n",
    "    upper_model = QuantileRegressor(\n",
    "        quantile=upper_quantile, \n",
    "        alpha=0.01, \n",
    "        solver='highs'\n",
    "    )\n",
    "    upper_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Dá»± Ä‘oÃ¡n\n",
    "    print(f\"   Making predictions...\")\n",
    "    lower_pred = lower_model.predict(X_test)\n",
    "    upper_pred = upper_model.predict(X_test)\n",
    "    \n",
    "    # Äáº£m báº£o lower <= upper\n",
    "    lower_pred = np.minimum(lower_pred, upper_pred)\n",
    "    upper_pred = np.maximum(lower_pred, upper_pred)\n",
    "    \n",
    "    return lower_pred, upper_pred, {'lower_model': lower_model, 'upper_model': upper_model}\n",
    "\n",
    "# Chia train/validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Huáº¥n luyá»‡n Quantile Regression\n",
    "qr_lower_val, qr_upper_val, qr_models = quantile_regression_approach(\n",
    "    X_train_split, y_train_split, X_val_split\n",
    ")\n",
    "\n",
    "# ÄÃ¡nh giÃ¡\n",
    "qr_metrics = pi_model.evaluate_intervals(y_val_split, qr_lower_val, qr_upper_val)\n",
    "print(f\"\\nðŸ“Š Quantile Regression Results:\")\n",
    "print(f\"   Mean Interval Width: {qr_metrics['mean_interval_width']:,.0f}\")\n",
    "print(f\"   Coverage Rate: {qr_metrics['coverage_rate']:.3f}\")\n",
    "print(f\"   Target Coverage: {qr_metrics['target_coverage']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PhÆ°Æ¡ng phÃ¡p 2: LightGBM Quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_quantile_approach(X_train, y_train, X_test, alpha=0.1):\n",
    "    \"\"\"PhÆ°Æ¡ng phÃ¡p LightGBM vá»›i quantile objective\"\"\"\n",
    "    lower_quantile = alpha / 2\n",
    "    upper_quantile = 1 - alpha / 2\n",
    "    \n",
    "    print(f\"ðŸ”§ Training LightGBM Quantile models...\")\n",
    "    \n",
    "    # Tham sá»‘ chung\n",
    "    base_params = {\n",
    "        'objective': 'quantile',\n",
    "        'metric': 'quantile',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Chuáº©n bá»‹ dá»¯ liá»‡u\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    \n",
    "    # Model cho quantile dÆ°á»›i\n",
    "    print(f\"   Training lower quantile model ({lower_quantile:.3f})...\")\n",
    "    lower_params = base_params.copy()\n",
    "    lower_params['alpha'] = lower_quantile\n",
    "    \n",
    "    lower_model = lgb.train(\n",
    "        lower_params, \n",
    "        train_data, \n",
    "        num_boost_round=1000,\n",
    "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Model cho quantile trÃªn\n",
    "    print(f\"   Training upper quantile model ({upper_quantile:.3f})...\")\n",
    "    upper_params = base_params.copy()\n",
    "    upper_params['alpha'] = upper_quantile\n",
    "    \n",
    "    upper_model = lgb.train(\n",
    "        upper_params, \n",
    "        train_data, \n",
    "        num_boost_round=1000,\n",
    "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Dá»± Ä‘oÃ¡n\n",
    "    print(f\"   Making predictions...\")\n",
    "    lower_pred = lower_model.predict(X_test, num_iteration=lower_model.best_iteration)\n",
    "    upper_pred = upper_model.predict(X_test, num_iteration=upper_model.best_iteration)\n",
    "    \n",
    "    # Äáº£m báº£o lower <= upper\n",
    "    lower_pred = np.minimum(lower_pred, upper_pred)\n",
    "    upper_pred = np.maximum(lower_pred, upper_pred)\n",
    "    \n",
    "    return lower_pred, upper_pred, {'lower_model': lower_model, 'upper_model': upper_model}\n",
    "\n",
    "# Huáº¥n luyá»‡n LightGBM\n",
    "lgb_lower_val, lgb_upper_val, lgb_models = lightgbm_quantile_approach(\n",
    "    X_train_split, y_train_split, X_val_split\n",
    ")\n",
    "\n",
    "# ÄÃ¡nh giÃ¡\n",
    "lgb_metrics = pi_model.evaluate_intervals(y_val_split, lgb_lower_val, lgb_upper_val)\n",
    "print(f\"\\nðŸ“Š LightGBM Quantile Results:\")\n",
    "print(f\"   Mean Interval Width: {lgb_metrics['mean_interval_width']:,.0f}\")\n",
    "print(f\"   Coverage Rate: {lgb_metrics['coverage_rate']:.3f}\")\n",
    "print(f\"   Target Coverage: {lgb_metrics['target_coverage']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PhÆ°Æ¡ng phÃ¡p 3: Ensemble vá»›i Uncertainty Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_uncertainty_approach(X_train, y_train, X_test, alpha=0.1):\n",
    "    \"\"\"PhÆ°Æ¡ng phÃ¡p Ensemble vá»›i Æ°á»›c tÃ­nh uncertainty\"\"\"\n",
    "    print(f\"ðŸ”§ Training Ensemble models...\")\n",
    "    \n",
    "    models = []\n",
    "    predictions = []\n",
    "    \n",
    "    # 1. Random Forest\n",
    "    print(f\"   Training Random Forest...\")\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    models.append(('RandomForest', rf))\n",
    "    predictions.append(rf_pred)\n",
    "    \n",
    "    # 2. Gradient Boosting\n",
    "    print(f\"   Training Gradient Boosting...\")\n",
    "    gb = GradientBoostingRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )\n",
    "    gb.fit(X_train, y_train)\n",
    "    gb_pred = gb.predict(X_test)\n",
    "    models.append(('GradientBoosting', gb))\n",
    "    predictions.append(gb_pred)\n",
    "    \n",
    "    # 3. XGBoost\n",
    "    print(f\"   Training XGBoost...\")\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_pred = xgb_model.predict(X_test)\n",
    "    models.append(('XGBoost', xgb_model))\n",
    "    predictions.append(xgb_pred)\n",
    "    \n",
    "    # TÃ­nh ensemble prediction\n",
    "    print(f\"   Computing ensemble predictions...\")\n",
    "    predictions = np.array(predictions)\n",
    "    ensemble_pred = np.mean(predictions, axis=0)\n",
    "    \n",
    "    # Æ¯á»›c tÃ­nh uncertainty tá»« variance cá»§a predictions\n",
    "    pred_std = np.std(predictions, axis=0)\n",
    "    \n",
    "    # TÃ­nh prediction intervals\n",
    "    z_score = stats.norm.ppf(1 - alpha/2)  # for confidence interval\n",
    "    \n",
    "    lower_pred = ensemble_pred - z_score * pred_std\n",
    "    upper_pred = ensemble_pred + z_score * pred_std\n",
    "    \n",
    "    return lower_pred, upper_pred, {\n",
    "        'models': models, \n",
    "        'ensemble_pred': ensemble_pred,\n",
    "        'pred_std': pred_std\n",
    "    }\n",
    "\n",
    "# Huáº¥n luyá»‡n Ensemble\n",
    "ens_lower_val, ens_upper_val, ens_models = ensemble_uncertainty_approach(\n",
    "    X_train_split, y_train_split, X_val_split\n",
    ")\n",
    "\n",
    "# ÄÃ¡nh giÃ¡\n",
    "ens_metrics = pi_model.evaluate_intervals(y_val_split, ens_lower_val, ens_upper_val)\n",
    "print(f\"\\nðŸ“Š Ensemble Uncertainty Results:\")\n",
    "print(f\"   Mean Interval Width: {ens_metrics['mean_interval_width']:,.0f}\")\n",
    "print(f\"   Coverage Rate: {ens_metrics['coverage_rate']:.3f}\")\n",
    "print(f\"   Target Coverage: {ens_metrics['target_coverage']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. So sÃ¡nh cÃ¡c PhÆ°Æ¡ng phÃ¡p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So sÃ¡nh káº¿t quáº£\n",
    "def compare_methods():\n",
    "    results = {\n",
    "        'Method': ['Quantile Regression', 'LightGBM Quantile', 'Ensemble Uncertainty'],\n",
    "        'Mean_Interval_Width': [\n",
    "            qr_metrics['mean_interval_width'],\n",
    "            lgb_metrics['mean_interval_width'],\n",
    "            ens_metrics['mean_interval_width']\n",
    "        ],\n",
    "        'Coverage_Rate': [\n",
    "            qr_metrics['coverage_rate'],\n",
    "            lgb_metrics['coverage_rate'],\n",
    "            ens_metrics['coverage_rate']\n",
    "        ],\n",
    "        'Coverage_Gap': [\n",
    "            abs(qr_metrics['coverage_rate'] - qr_metrics['target_coverage']),\n",
    "            abs(lgb_metrics['coverage_rate'] - lgb_metrics['target_coverage']),\n",
    "            abs(ens_metrics['coverage_rate'] - ens_metrics['target_coverage'])\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    comparison_df = pd.DataFrame(results)\n",
    "    comparison_df['Rank_Width'] = comparison_df['Mean_Interval_Width'].rank()\n",
    "    comparison_df['Rank_Coverage'] = comparison_df['Coverage_Gap'].rank()\n",
    "    comparison_df['Overall_Score'] = comparison_df['Rank_Width'] + comparison_df['Rank_Coverage']\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"                    SO SÃNH CÃC PHÆ¯Æ NG PHÃP\")\n",
    "    print(\"=\"*80)\n",
    "    print(comparison_df.round(3))\n",
    "    \n",
    "    # TÃ¬m phÆ°Æ¡ng phÃ¡p tá»‘t nháº¥t\n",
    "    best_method_idx = comparison_df['Overall_Score'].idxmin()\n",
    "    best_method = comparison_df.loc[best_method_idx, 'Method']\n",
    "    \n",
    "    print(f\"\\nðŸ† PHÆ¯Æ NG PHÃP Tá»T NHáº¤T: {best_method}\")\n",
    "    print(f\"   â€¢ Mean Interval Width: {comparison_df.loc[best_method_idx, 'Mean_Interval_Width']:,.0f}\")\n",
    "    print(f\"   â€¢ Coverage Rate: {comparison_df.loc[best_method_idx, 'Coverage_Rate']:.3f}\")\n",
    "    \n",
    "    return comparison_df, best_method\n",
    "\n",
    "comparison_results, best_method = compare_methods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Interval Width Comparison\n",
    "methods = comparison_results['Method']\n",
    "widths = comparison_results['Mean_Interval_Width']\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
    "\n",
    "axes[0,0].bar(methods, widths, color=colors)\n",
    "axes[0,0].set_title('Mean Interval Width Comparison', fontweight='bold')\n",
    "axes[0,0].set_ylabel('Mean Interval Width ($)')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(widths):\n",
    "    axes[0,0].text(i, v + max(widths)*0.01, f'{v:,.0f}', ha='center', va='bottom')\n",
    "\n",
    "# 2. Coverage Rate Comparison\n",
    "coverage_rates = comparison_results['Coverage_Rate']\n",
    "target_coverage = 0.9\n",
    "\n",
    "axes[0,1].bar(methods, coverage_rates, color=colors)\n",
    "axes[0,1].axhline(y=target_coverage, color='red', linestyle='--', label=f'Target: {target_coverage:.1%}')\n",
    "axes[0,1].set_title('Coverage Rate Comparison', fontweight='bold')\n",
    "axes[0,1].set_ylabel('Coverage Rate')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "axes[0,1].legend()\n",
    "for i, v in enumerate(coverage_rates):\n",
    "    axes[0,1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 3. Prediction Intervals Visualization (sample)\n",
    "sample_size = 50\n",
    "sample_idx = np.random.choice(len(y_val_split), sample_size, replace=False)\n",
    "x_pos = np.arange(sample_size)\n",
    "\n",
    "axes[1,0].scatter(x_pos, y_val_split.iloc[sample_idx], color='red', label='True Values', s=30, alpha=0.7)\n",
    "axes[1,0].fill_between(x_pos, lgb_lower_val[sample_idx], lgb_upper_val[sample_idx], \n",
    "                       alpha=0.3, color='blue', label='LightGBM Intervals')\n",
    "axes[1,0].set_title('Sample Prediction Intervals (LightGBM)', fontweight='bold')\n",
    "axes[1,0].set_xlabel('Sample Index')\n",
    "axes[1,0].set_ylabel('Sale Price ($)')\n",
    "axes[1,0].legend()\n",
    "\n",
    "# 4. Residuals Analysis\n",
    "lgb_center = (lgb_lower_val + lgb_upper_val) / 2\n",
    "residuals = y_val_split - lgb_center\n",
    "\n",
    "axes[1,1].scatter(lgb_center, residuals, alpha=0.6)\n",
    "axes[1,1].axhline(y=0, color='red', linestyle='--')\n",
    "axes[1,1].set_title('Residuals vs Predicted (LightGBM)', fontweight='bold')\n",
    "axes[1,1].set_xlabel('Predicted Center')\n",
    "axes[1,1].set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation cho phÆ°Æ¡ng phÃ¡p tá»‘t nháº¥t\n",
    "def cross_validate_prediction_intervals(X, y, method='lightgbm', cv_folds=5):\n",
    "    \"\"\"Cross-validation cho prediction intervals\"\"\"\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    cv_widths = []\n",
    "    cv_coverages = []\n",
    "    \n",
    "    print(f\"ðŸ”„ Running {cv_folds}-fold Cross-Validation for {method}...\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"   Fold {fold + 1}/{cv_folds}...\")\n",
    "        \n",
    "        X_train_cv = X.iloc[train_idx]\n",
    "        X_val_cv = X.iloc[val_idx]\n",
    "        y_train_cv = y.iloc[train_idx]\n",
    "        y_val_cv = y.iloc[val_idx]\n",
    "        \n",
    "        if method == 'lightgbm':\n",
    "            lower_pred, upper_pred, _ = lightgbm_quantile_approach(\n",
    "                X_train_cv, y_train_cv, X_val_cv\n",
    "            )\n",
    "        elif method == 'quantile':\n",
    "            lower_pred, upper_pred, _ = quantile_regression_approach(\n",
    "                X_train_cv, y_train_cv, X_val_cv\n",
    "            )\n",
    "        elif method == 'ensemble':\n",
    "            lower_pred, upper_pred, _ = ensemble_uncertainty_approach(\n",
    "                X_train_cv, y_train_cv, X_val_cv\n",
    "            )\n",
    "        \n",
    "        # ÄÃ¡nh giÃ¡ fold nÃ y\n",
    "        width = np.mean(upper_pred - lower_pred)\n",
    "        coverage = np.mean((y_val_cv >= lower_pred) & (y_val_cv <= upper_pred))\n",
    "        \n",
    "        cv_widths.append(width)\n",
    "        cv_coverages.append(coverage)\n",
    "    \n",
    "    # Tá»•ng há»£p káº¿t quáº£\n",
    "    cv_results = {\n",
    "        'mean_width': np.mean(cv_widths),\n",
    "        'std_width': np.std(cv_widths),\n",
    "        'mean_coverage': np.mean(cv_coverages),\n",
    "        'std_coverage': np.std(cv_coverages),\n",
    "        'fold_widths': cv_widths,\n",
    "        'fold_coverages': cv_coverages\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Cross-Validation Results ({method}):\")\n",
    "    print(f\"   Mean Interval Width: {cv_results['mean_width']:,.0f} Â± {cv_results['std_width']:,.0f}\")\n",
    "    print(f\"   Mean Coverage Rate: {cv_results['mean_coverage']:.3f} Â± {cv_results['std_coverage']:.3f}\")\n",
    "    \n",
    "    return cv_results\n",
    "\n",
    "# Cháº¡y CV cho phÆ°Æ¡ng phÃ¡p tá»‘t nháº¥t\n",
    "if 'LightGBM' in best_method:\n",
    "    cv_results = cross_validate_prediction_intervals(X_train, y_train, 'lightgbm')\n",
    "elif 'Quantile' in best_method:\n",
    "    cv_results = cross_validate_prediction_intervals(X_train, y_train, 'quantile')\n",
    "else:\n",
    "    cv_results = cross_validate_prediction_intervals(X_train, y_train, 'ensemble')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Model Training vÃ  Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huáº¥n luyá»‡n mÃ´ hÃ¬nh cuá»‘i cÃ¹ng trÃªn toÃ n bá»™ training data\n",
    "print(f\"ðŸš€ Training final model on full training data...\")\n",
    "\n",
    "if 'LightGBM' in best_method:\n",
    "    final_lower, final_upper, final_models = lightgbm_quantile_approach(\n",
    "        X_train, y_train, X_test\n",
    "    )\n",
    "    model_type = 'lightgbm'\n",
    "elif 'Quantile' in best_method:\n",
    "    final_lower, final_upper, final_models = quantile_regression_approach(\n",
    "        X_train, y_train, X_test\n",
    "    )\n",
    "    model_type = 'quantile'\n",
    "else:\n",
    "    final_lower, final_upper, final_models = ensemble_uncertainty_approach(\n",
    "        X_train, y_train, X_test\n",
    "    )\n",
    "    model_type = 'ensemble'\n",
    "\n",
    "print(f\"âœ… Final model training completed!\")\n",
    "print(f\"   Test predictions shape: {final_lower.shape}\")\n",
    "print(f\"   Mean interval width: {np.mean(final_upper - final_lower):,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Táº¡o Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o submission file cho Kaggle\n",
    "def create_submission(lower_pred, upper_pred, test_ids=None):\n",
    "    \"\"\"Táº¡o file submission cho Kaggle\"\"\"\n",
    "    \n",
    "    # Náº¿u khÃ´ng cÃ³ test_ids, táº¡o ID giáº£\n",
    "    if test_ids is None:\n",
    "        test_ids = range(len(lower_pred))\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'Id': test_ids,\n",
    "        'lower': lower_pred,\n",
    "        'upper': upper_pred\n",
    "    })\n",
    "    \n",
    "    # Äáº£m báº£o lower <= upper\n",
    "    submission['lower'] = np.minimum(submission['lower'], submission['upper'])\n",
    "    submission['upper'] = np.maximum(submission['lower'], submission['upper'])\n",
    "    \n",
    "    # LÃ m trÃ²n\n",
    "    submission['lower'] = submission['lower'].round(2)\n",
    "    submission['upper'] = submission['upper'].round(2)\n",
    "    \n",
    "    return submission\n",
    "\n",
    "# Táº¡o submission\n",
    "try:\n",
    "    # Thá»­ load test IDs tá»« file gá»‘c\n",
    "    test_df_original = pd.read_csv('test.csv')\n",
    "    test_ids = test_df_original['Id'].values if 'Id' in test_df_original.columns else None\n",
    "except:\n",
    "    test_ids = None\n",
    "\n",
    "submission = create_submission(final_lower, final_upper, test_ids)\n",
    "\n",
    "# LÆ°u submission\n",
    "submission_filename = f'submission_{model_type}_{pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"ðŸ“„ Submission file created: {submission_filename}\")\n",
    "print(f\"   Shape: {submission.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(submission.head())\n",
    "\n",
    "print(f\"\\nðŸ“Š Submission Statistics:\")\n",
    "print(f\"   Mean lower bound: ${submission['lower'].mean():,.0f}\")\n",
    "print(f\"   Mean upper bound: ${submission['upper'].mean():,.0f}\")\n",
    "print(f\"   Mean interval width: ${(submission['upper'] - submission['lower']).mean():,.0f}\")\n",
    "print(f\"   Min interval width: ${(submission['upper'] - submission['lower']).min():,.0f}\")\n",
    "print(f\"   Max interval width: ${(submission['upper'] - submission['lower']).max():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Interpretation vÃ  Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "def analyze_feature_importance(models, model_type, feature_names):\n",
    "    \"\"\"PhÃ¢n tÃ­ch feature importance\"\"\"\n",
    "    \n",
    "    if model_type == 'lightgbm':\n",
    "        # LightGBM feature importance\n",
    "        lower_importance = models['lower_model'].feature_importance(importance_type='gain')\n",
    "        upper_importance = models['upper_model'].feature_importance(importance_type='gain')\n",
    "        \n",
    "        # Trung bÃ¬nh cá»§a lower vÃ  upper\n",
    "        avg_importance = (lower_importance + upper_importance) / 2\n",
    "        \n",
    "        feature_imp = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': avg_importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "    elif model_type == 'quantile':\n",
    "        # Quantile regression coefficients\n",
    "        lower_coef = np.abs(models['lower_model'].coef_)\n",
    "        upper_coef = np.abs(models['upper_model'].coef_)\n",
    "        \n",
    "        avg_coef = (lower_coef + upper_coef) / 2\n",
    "        \n",
    "        feature_imp = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': avg_coef\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "    elif model_type == 'ensemble':\n",
    "        # Ensemble feature importance\n",
    "        importances = []\n",
    "        for name, model in models['models']:\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                importances.append(model.feature_importances_)\n",
    "        \n",
    "        if importances:\n",
    "            avg_importance = np.mean(importances, axis=0)\n",
    "            feature_imp = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': avg_importance\n",
    "            }).sort_values('importance', ascending=False)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    return feature_imp\n",
    "\n",
    "# PhÃ¢n tÃ­ch feature importance\n",
    "feature_names = X_train.columns.tolist()\n",
    "feature_importance = analyze_feature_importance(final_models, model_type, feature_names)\n",
    "\n",
    "if feature_importance is not None:\n",
    "    print(\"ðŸ” TOP 15 FEATURES QUAN TRá»ŒNG NHáº¤T:\")\n",
    "    print(feature_importance.head(15))\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(20)\n",
    "    \n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 20 Feature Importance ({model_type.upper()})', fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âŒ Could not extract feature importance for this model type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. LÆ°u Models vÃ  Káº¿t quáº£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LÆ°u models vÃ  káº¿t quáº£\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# LÆ°u models\n",
    "if model_type == 'lightgbm':\n",
    "    final_models['lower_model'].save_model('models/lgb_lower_model.txt')\n",
    "    final_models['upper_model'].save_model('models/lgb_upper_model.txt')\n",
    "else:\n",
    "    joblib.dump(final_models, f'models/{model_type}_models.pkl')\n",
    "\n",
    "# LÆ°u káº¿t quáº£\n",
    "results_summary = {\n",
    "    'best_method': best_method,\n",
    "    'model_type': model_type,\n",
    "    'cv_results': cv_results,\n",
    "    'comparison_results': comparison_results.to_dict(),\n",
    "    'submission_stats': {\n",
    "        'mean_interval_width': float((submission['upper'] - submission['lower']).mean()),\n",
    "        'min_interval_width': float((submission['upper'] - submission['lower']).min()),\n",
    "        'max_interval_width': float((submission['upper'] - submission['lower']).max())\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('results/model_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "if feature_importance is not None:\n",
    "    feature_importance.to_csv('results/feature_importance.csv', index=False)\n",
    "\n",
    "print(\"ðŸ’¾ Models vÃ  káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u:\")\n",
    "print(f\"   â€¢ Models: models/{model_type}_*\")\n",
    "print(f\"   â€¢ Results: results/model_results.json\")\n",
    "print(f\"   â€¢ Feature importance: results/feature_importance.csv\")\n",
    "print(f\"   â€¢ Submission: {submission_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. TÃ³m táº¯t vÃ  Káº¿t luáº­n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TÃ³m táº¯t cuá»‘i cÃ¹ng\n",
    "def final_summary():\n",
    "    print(\"=\"*80)\n",
    "    print(\"                    TÃ“M Táº®T Dá»° ÃN PREDICTION INTERVALS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Má»¤C TIÃŠU:\")\n",
    "    print(f\"   â€¢ XÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n khoáº£ng giÃ¡ nhÃ  (90% confidence interval)\")\n",
    "    print(f\"   â€¢ Tá»‘i thiá»ƒu hÃ³a Mean Interval Width trÃªn Kaggle\")\n",
    "    print(f\"   â€¢ Äáº£m báº£o coverage rate â‰¥ 90%\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š PHÆ¯Æ NG PHÃP ÄÃƒ THá»°C HIá»†N:\")\n",
    "    print(f\"   1. Quantile Regression\")\n",
    "    print(f\"   2. LightGBM Quantile\")\n",
    "    print(f\"   3. Ensemble vá»›i Uncertainty Estimation\")\n",
    "    \n",
    "    print(f\"\\nðŸ† Ká»‚T QUáº¢ Tá»T NHáº¤T:\")\n",
    "    print(f\"   â€¢ PhÆ°Æ¡ng phÃ¡p: {best_method}\")\n",
    "    print(f\"   â€¢ Mean Interval Width: {cv_results['mean_width']:,.0f} Â± {cv_results['std_width']:,.0f}\")\n",
    "    print(f\"   â€¢ Coverage Rate: {cv_results['mean_coverage']:.3f} Â± {cv_results['std_coverage']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ SUBMISSION KAGGLE:\")\n",
    "    print(f\"   â€¢ File: {submission_filename}\")\n",
    "    print(f\"   â€¢ Samples: {len(submission)}\")\n",
    "    print(f\"   â€¢ Mean Interval Width: ${(submission['upper'] - submission['lower']).mean():,.0f}\")\n",
    "    \n",
    "    if feature_importance is not None:\n",
    "        print(f\"\\nðŸ” TOP 5 FEATURES QUAN TRá»ŒNG:\")\n",
    "        for i, (_, row) in enumerate(feature_importance.head(5).iterrows()):\n",
    "            print(f\"   {i+1}. {row['feature']}: {row['importance']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nâœ… DELIVERABLES:\")\n",
    "    print(f\"   â€¢ EDA notebook (Q1)\")\n",
    "    print(f\"   â€¢ Model training notebook (Q2)\")\n",
    "    print(f\"   â€¢ Trained models\")\n",
    "    print(f\"   â€¢ Kaggle submission file\")\n",
    "    print(f\"   â€¢ Feature importance analysis\")\n",
    "    \n",
    "    print(f\"\\nðŸš€ NEXT STEPS:\")\n",
    "    print(f\"   1. Submit {submission_filename} to Kaggle\")\n",
    "    print(f\"   2. Monitor leaderboard performance\")\n",
    "    print(f\"   3. Iterate and improve based on feedback\")\n",
    "    print(f\"   4. Prepare final report and presentation\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "final_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}